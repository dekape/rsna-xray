{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMvZ3r7PG0-T",
        "outputId": "3b583fe7-15a3-4393-d965-19401e224903"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e06P0RzAHIQX",
        "outputId": "5584a1b7-c1f4-4a31-f5ad-a23a61b3436d"
      },
      "source": [
        "!pip install wandb -qqq\n",
        "%cd 'path/to/scripts/here'\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import wandb\n",
        "\n",
        "import torch\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, RandomRotation, ToPILImage\n",
        "\n",
        "from networks import *\n",
        "from datasets import *\n",
        "from utils import *"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/IC_PHD/GTA/ACSE20-21/ACSE4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JxjObfFHMhM"
      },
      "source": [
        "    # Set test transforms for normalisation \n",
        "    test_transform = Compose([\n",
        "        Normalize(mean=[0.5064], std=[0.2493])\n",
        "    ])\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6-nw_t9IDez",
        "outputId": "49a28321-39d7-4329-86bb-c2c3c4a6cea8"
      },
      "source": [
        "# Set training static parameters and hyperparameters\n",
        "parameters = dict(\n",
        "    data_name=\"xray-data\",                                                     # will search folder ./{data_name}/train and ./{data_name}/test\n",
        "    target_code={\"covid\":0, \"lung_opacity\":1, \"pneumonia\":2, \"normal\":3},      # each key should be a subfolder with the training data ./{data_name}/train/{key}\n",
        "    input_height=299,\n",
        "    input_width=299,\n",
        "    input_channels=1,\n",
        "    \n",
        "    test_batch_size=64,\n",
        "    \n",
        "    model_name=\"ResNet18_FeatureExtract\",                                      # will search model in networks.py, must be a subclass of nn.Module and take as input param \"num_classes\" referring to the number of classes for classification\n",
        "    dataset=\"XRAY3C_TensorDataset\",                                            # will search dataset in datasets.py, must be a subclass of torch.utils.data.Dataset, inputs must be img_paths, targets and transform, output of __getitem__ must be an image sample (C, H, W) and its target\n",
        "    \n",
        "    test_transform=test_transform,\n",
        "    device=set_device(\"cuda\"),\n",
        "    )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU Tesla V100-SXM2-16GB!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkTFfjPCYhWm",
        "outputId": "9174cffe-8952-417d-8da3-4eb25f218211"
      },
      "source": [
        "# set up offline wandb config\n",
        "config = setup_config_offline(parameters)\n",
        "\n",
        "# Set seed\n",
        "set_seed(42)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u4HmSlrIGxm",
        "outputId": "40b3dcd1-f062-4ec3-eab7-ee49ae26fbb6"
      },
      "source": [
        "# Set up evaluation with parameters, and load trained model\n",
        "path_to_trained_model = os.path.join(\".\", \"wandb\", \"run-20210421_144638-29js5gok\", \"files\", \"young-plasma-45_epoch15.pth\")\n",
        "model, test_ds  = set_up_test(config, path_to_model=path_to_trained_model, test_transform=parameters[\"test_transform\"])\n",
        "\n",
        "# Get Predictions\n",
        "print(\"\\n Predicting...\")\n",
        "img_paths, y_preds = predict(model=model, dataset=test_ds, config=config)\n",
        "\n",
        "# Save predictions to csv file\n",
        "print(\"\\n Saving prediction file...\")\n",
        "img_names = [pth.split(\"/\")[-1].split(\".\")[0] for pth in img_paths]\n",
        "save_preds_csv(img_names, y_preds, filename=\"prediction.csv\")\n",
        "print(\"\\n DONE!\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading image paths in ./xray-data/test\n",
            "Loading model:  ./wandb/run-20210421_144638-29js5gok/files/young-plasma-45_epoch15.pth\n",
            " data_name                                     :                     xray-data\n",
            " target_code                                   :               {'covid': 0, 'lung_opacity': 1, 'pneumonia': 2, 'normal': 3}\n",
            " input_height                                  :                           299\n",
            " input_width                                   :                           299\n",
            " input_channels                                :                             1\n",
            " test_batch_size                               :                            64\n",
            " model_name                                    :               ResNet18_FeatureExtract\n",
            " dataset                                       :               XRAY3C_TensorDataset\n",
            " test_transform                                :               Compose(\n",
            "    Normalize(mean=[0.5064], std=[0.2493])\n",
            ")\n",
            " device                                        :                          cuda\n",
            " model                                         :               ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
            ")\n",
            " Total test samples                            :                           950\n",
            "\n",
            " Predicting...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (950 of 950) |######################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Saving prediction file...\n",
            "\n",
            " DONE!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo4wR4LDKZgS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "417ddc59-bff6-4ca5-fbde-6befa148e825"
      },
      "source": [
        "# ! NOTE STUDENTS WON'T HAVE ACCESS TO THE test_key.csv FILE\n",
        "key_filepath = os.path.join(\".\", \"test_key.csv\")\n",
        "pred_filepath = os.path.join(\".\", \"prediction.csv\")\n",
        "acc, keydf, testdf = get_pred_acc(key_filepath, pred_filepath)    \n",
        "\n",
        "cat = pd.merge(keydf, testdf, on=['name'], how='inner')\n",
        "print(cat)\n",
        "print(\"\\n\\n ACCURACY: \", acc)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         name  target_x  target_y\n",
            "0      test_0         1         3\n",
            "1      test_1         3         3\n",
            "2      test_2         1         3\n",
            "3      test_3         3         3\n",
            "4      test_4         3         3\n",
            "..        ...       ...       ...\n",
            "945  test_945         3         3\n",
            "946  test_946         1         3\n",
            "947  test_947         3         3\n",
            "948  test_948         1         3\n",
            "949  test_949         3         3\n",
            "\n",
            "[950 rows x 3 columns]\n",
            "\n",
            "\n",
            " ACCURACY:  0.8621052631578947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri-gf1qOd1dj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}